----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: ./datasets/sketchy            	[default: None]
             dataset_mode: aligned                       
                direction: BtoA                          	[default: AtoB]
              display_env: main                          
             display_freq: 400                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                lambda_L1: 100.0                         
                load_iter: 0                             	[default: 0]
                load_size: 286                           
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: pix2pix                       	[default: cycle_gan]
                 n_epochs: 100                           
           n_epochs_decay: 100                           
               n_layers_D: 3                             
                     name: sketchy_pix2pix               	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                  no_html: False                         
                     norm: batch                         
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 0                             
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                  verbose: False                         
----------------- End -------------------
dataset [AlignedDataset] was created
The number of training images = 22
initialize network with normal
initialize network with normal
model [Pix2PixModel] was created
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
[Network D] Total number of parameters : 2.769 M
-----------------------------------------------
create web directory ./checkpoints/sketchy_pix2pix/web...
learning rate 0.0002000 -> 0.0002000
/home2/gftw82/pix2pixenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
End of epoch 1 / 200 	 Time Taken: 2 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 5, iters: 12, time: 0.056, data: 0.284) G_GAN: 3.959 G_L1: 14.101 D_real: 0.041 D_fake: 1.162 
saving the model at the end of epoch 5, iters 110
End of epoch 5 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 6 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 7 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 8 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 9 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 10, iters: 2, time: 0.050, data: 0.001) G_GAN: 3.344 G_L1: 8.371 D_real: 0.003 D_fake: 0.045 
saving the model at the end of epoch 10, iters 220
End of epoch 10 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 11 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 12 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 13 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 14, iters: 14, time: 0.056, data: 0.000) G_GAN: 5.680 G_L1: 8.961 D_real: 0.001 D_fake: 0.004 
End of epoch 14 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 15, iters 330
End of epoch 15 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 16 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 17 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 18 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 19, iters: 4, time: 0.174, data: 0.001) G_GAN: 3.663 G_L1: 9.426 D_real: 0.002 D_fake: 0.049 
End of epoch 19 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 20, iters 440
End of epoch 20 / 200 	 Time Taken: 2 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 21 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 22 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 23, iters: 16, time: 0.053, data: 0.000) G_GAN: 5.138 G_L1: 9.140 D_real: 0.003 D_fake: 0.014 
End of epoch 23 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 24 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 25, iters 550
End of epoch 25 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 26 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 27 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 28, iters: 6, time: 0.057, data: 0.002) G_GAN: 3.279 G_L1: 4.609 D_real: 0.003 D_fake: 0.016 
End of epoch 28 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 29 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 30, iters 660
End of epoch 30 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 31 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 32, iters: 18, time: 0.051, data: 0.000) G_GAN: 5.313 G_L1: 6.137 D_real: 0.002 D_fake: 0.006 
End of epoch 32 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 33 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 34 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 35, iters 770
End of epoch 35 / 200 	 Time Taken: 4 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 36 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 37, iters: 8, time: 0.196, data: 0.001) G_GAN: 3.738 G_L1: 8.908 D_real: 0.004 D_fake: 0.512 
End of epoch 37 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 38 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 39 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 40, iters 880
End of epoch 40 / 200 	 Time Taken: 5 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 41, iters: 20, time: 0.055, data: 0.001) G_GAN: 4.991 G_L1: 5.820 D_real: 0.752 D_fake: 0.003 
End of epoch 41 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 42 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 43 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 44 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 45, iters 990
End of epoch 45 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 46, iters: 10, time: 0.057, data: 0.001) G_GAN: 5.548 G_L1: 5.459 D_real: 2.115 D_fake: 0.001 
End of epoch 46 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 47 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 48 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 49 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 50, iters: 22, time: 0.056, data: 0.002) G_GAN: 6.571 G_L1: 5.454 D_real: 0.071 D_fake: 0.001 
saving the model at the end of epoch 50, iters 1100
End of epoch 50 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 51 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 52 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 53 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 54 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 55, iters: 12, time: 0.243, data: 0.245) G_GAN: 3.225 G_L1: 11.179 D_real: 0.017 D_fake: 0.047 
saving the model at the end of epoch 55, iters 1210
End of epoch 55 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 56 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 57 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 58 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 59 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 60, iters: 2, time: 0.057, data: 0.002) G_GAN: 4.242 G_L1: 10.199 D_real: 0.019 D_fake: 0.018 
saving the model at the end of epoch 60, iters 1320
End of epoch 60 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 61 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 62 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 63 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 64, iters: 14, time: 0.056, data: 0.000) G_GAN: 1.363 G_L1: 7.931 D_real: 1.632 D_fake: 0.019 
End of epoch 64 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 65, iters 1430
End of epoch 65 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 66 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 67 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 68 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 69, iters: 4, time: 0.056, data: 0.001) G_GAN: 3.408 G_L1: 12.203 D_real: 0.007 D_fake: 0.292 
End of epoch 69 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 70, iters 1540
End of epoch 70 / 200 	 Time Taken: 9 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 71 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 72 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 73, iters: 16, time: 0.307, data: 0.000) G_GAN: 3.920 G_L1: 12.009 D_real: 0.008 D_fake: 0.086 
End of epoch 73 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 74 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 75, iters 1650
End of epoch 75 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 76 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 77 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 78, iters: 6, time: 0.057, data: 0.002) G_GAN: 4.788 G_L1: 21.273 D_real: 0.002 D_fake: 0.017 
End of epoch 78 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 79 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 80, iters 1760
End of epoch 80 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 81 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 82, iters: 18, time: 0.056, data: 0.001) G_GAN: 3.441 G_L1: 20.990 D_real: 0.001 D_fake: 0.312 
End of epoch 82 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 83 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 84 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 85, iters 1870
End of epoch 85 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 86 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 87, iters: 8, time: 0.057, data: 0.002) G_GAN: 0.606 G_L1: 6.542 D_real: 1.351 D_fake: 0.076 
End of epoch 87 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 88 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 89 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 90, iters 1980
End of epoch 90 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 91, iters: 20, time: 0.332, data: 0.002) G_GAN: 4.976 G_L1: 9.666 D_real: 0.209 D_fake: 0.008 
End of epoch 91 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 92 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 93 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 94 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
saving the model at the end of epoch 95, iters 2090
End of epoch 95 / 200 	 Time Taken: 3 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 96, iters: 10, time: 0.059, data: 0.001) G_GAN: 3.782 G_L1: 13.215 D_real: 0.003 D_fake: 0.087 
End of epoch 96 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 97 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 98 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0002000
End of epoch 99 / 200 	 Time Taken: 1 sec
learning rate 0.0002000 -> 0.0001980
(epoch: 100, iters: 22, time: 0.056, data: 0.001) G_GAN: 1.432 G_L1: 7.837 D_real: 0.118 D_fake: 0.650 
saving the model at the end of epoch 100, iters 2200
End of epoch 100 / 200 	 Time Taken: 3 sec
learning rate 0.0001980 -> 0.0001960
End of epoch 101 / 200 	 Time Taken: 1 sec
learning rate 0.0001960 -> 0.0001941
End of epoch 102 / 200 	 Time Taken: 1 sec
learning rate 0.0001941 -> 0.0001921
End of epoch 103 / 200 	 Time Taken: 1 sec
learning rate 0.0001921 -> 0.0001901
End of epoch 104 / 200 	 Time Taken: 1 sec
learning rate 0.0001901 -> 0.0001881
(epoch: 105, iters: 12, time: 0.057, data: 0.252) G_GAN: 3.233 G_L1: 11.028 D_real: 0.020 D_fake: 0.115 
saving the model at the end of epoch 105, iters 2310
End of epoch 105 / 200 	 Time Taken: 3 sec
learning rate 0.0001881 -> 0.0001861
End of epoch 106 / 200 	 Time Taken: 1 sec
learning rate 0.0001861 -> 0.0001842
End of epoch 107 / 200 	 Time Taken: 1 sec
learning rate 0.0001842 -> 0.0001822
End of epoch 108 / 200 	 Time Taken: 1 sec
learning rate 0.0001822 -> 0.0001802
End of epoch 109 / 200 	 Time Taken: 1 sec
learning rate 0.0001802 -> 0.0001782
(epoch: 110, iters: 2, time: 0.362, data: 0.001) G_GAN: 3.773 G_L1: 9.173 D_real: 0.017 D_fake: 0.054 
saving the model at the end of epoch 110, iters 2420
End of epoch 110 / 200 	 Time Taken: 3 sec
learning rate 0.0001782 -> 0.0001762
End of epoch 111 / 200 	 Time Taken: 1 sec
learning rate 0.0001762 -> 0.0001743
End of epoch 112 / 200 	 Time Taken: 1 sec
learning rate 0.0001743 -> 0.0001723
End of epoch 113 / 200 	 Time Taken: 1 sec
learning rate 0.0001723 -> 0.0001703
(epoch: 114, iters: 14, time: 0.056, data: 0.001) G_GAN: 2.271 G_L1: 8.305 D_real: 0.125 D_fake: 0.183 
End of epoch 114 / 200 	 Time Taken: 1 sec
learning rate 0.0001703 -> 0.0001683
saving the model at the end of epoch 115, iters 2530
End of epoch 115 / 200 	 Time Taken: 3 sec
learning rate 0.0001683 -> 0.0001663
End of epoch 116 / 200 	 Time Taken: 1 sec
learning rate 0.0001663 -> 0.0001644
End of epoch 117 / 200 	 Time Taken: 1 sec
learning rate 0.0001644 -> 0.0001624
End of epoch 118 / 200 	 Time Taken: 1 sec
learning rate 0.0001624 -> 0.0001604
(epoch: 119, iters: 4, time: 0.057, data: 0.001) G_GAN: 2.760 G_L1: 11.512 D_real: 0.011 D_fake: 0.165 
End of epoch 119 / 200 	 Time Taken: 1 sec
learning rate 0.0001604 -> 0.0001584
saving the model at the end of epoch 120, iters 2640
End of epoch 120 / 200 	 Time Taken: 11 sec
learning rate 0.0001584 -> 0.0001564
End of epoch 121 / 200 	 Time Taken: 1 sec
learning rate 0.0001564 -> 0.0001545
End of epoch 122 / 200 	 Time Taken: 1 sec
learning rate 0.0001545 -> 0.0001525
(epoch: 123, iters: 16, time: 0.055, data: 0.001) G_GAN: 4.960 G_L1: 10.365 D_real: 0.034 D_fake: 0.019 
End of epoch 123 / 200 	 Time Taken: 1 sec
learning rate 0.0001525 -> 0.0001505
End of epoch 124 / 200 	 Time Taken: 1 sec
learning rate 0.0001505 -> 0.0001485
saving the model at the end of epoch 125, iters 2750
End of epoch 125 / 200 	 Time Taken: 3 sec
learning rate 0.0001485 -> 0.0001465
End of epoch 126 / 200 	 Time Taken: 1 sec
learning rate 0.0001465 -> 0.0001446
End of epoch 127 / 200 	 Time Taken: 1 sec
learning rate 0.0001446 -> 0.0001426
(epoch: 128, iters: 6, time: 0.443, data: 0.001) G_GAN: 2.359 G_L1: 9.768 D_real: 0.130 D_fake: 1.100 
End of epoch 128 / 200 	 Time Taken: 1 sec
learning rate 0.0001426 -> 0.0001406
End of epoch 129 / 200 	 Time Taken: 1 sec
learning rate 0.0001406 -> 0.0001386
saving the model at the end of epoch 130, iters 2860
End of epoch 130 / 200 	 Time Taken: 2 sec
learning rate 0.0001386 -> 0.0001366
End of epoch 131 / 200 	 Time Taken: 1 sec
learning rate 0.0001366 -> 0.0001347
(epoch: 132, iters: 18, time: 0.054, data: 0.001) G_GAN: 1.038 G_L1: 8.356 D_real: 0.923 D_fake: 0.122 
End of epoch 132 / 200 	 Time Taken: 1 sec
learning rate 0.0001347 -> 0.0001327
End of epoch 133 / 200 	 Time Taken: 1 sec
learning rate 0.0001327 -> 0.0001307
End of epoch 134 / 200 	 Time Taken: 1 sec
learning rate 0.0001307 -> 0.0001287
saving the model at the end of epoch 135, iters 2970
End of epoch 135 / 200 	 Time Taken: 3 sec
learning rate 0.0001287 -> 0.0001267
End of epoch 136 / 200 	 Time Taken: 1 sec
learning rate 0.0001267 -> 0.0001248
(epoch: 137, iters: 8, time: 0.058, data: 0.001) G_GAN: 1.430 G_L1: 10.751 D_real: 0.570 D_fake: 0.151 
End of epoch 137 / 200 	 Time Taken: 1 sec
learning rate 0.0001248 -> 0.0001228
End of epoch 138 / 200 	 Time Taken: 1 sec
learning rate 0.0001228 -> 0.0001208
End of epoch 139 / 200 	 Time Taken: 1 sec
learning rate 0.0001208 -> 0.0001188
saving the model at the end of epoch 140, iters 3080
End of epoch 140 / 200 	 Time Taken: 3 sec
learning rate 0.0001188 -> 0.0001168
(epoch: 141, iters: 20, time: 0.056, data: 0.001) G_GAN: 2.483 G_L1: 9.034 D_real: 0.178 D_fake: 0.368 
End of epoch 141 / 200 	 Time Taken: 1 sec
learning rate 0.0001168 -> 0.0001149
End of epoch 142 / 200 	 Time Taken: 1 sec
learning rate 0.0001149 -> 0.0001129
End of epoch 143 / 200 	 Time Taken: 1 sec
learning rate 0.0001129 -> 0.0001109
End of epoch 144 / 200 	 Time Taken: 1 sec
learning rate 0.0001109 -> 0.0001089
saving the model at the end of epoch 145, iters 3190
End of epoch 145 / 200 	 Time Taken: 11 sec
learning rate 0.0001089 -> 0.0001069
(epoch: 146, iters: 10, time: 0.615, data: 0.001) G_GAN: 1.750 G_L1: 11.956 D_real: 0.002 D_fake: 0.552 
End of epoch 146 / 200 	 Time Taken: 1 sec
learning rate 0.0001069 -> 0.0001050
End of epoch 147 / 200 	 Time Taken: 1 sec
learning rate 0.0001050 -> 0.0001030
End of epoch 148 / 200 	 Time Taken: 1 sec
learning rate 0.0001030 -> 0.0001010
End of epoch 149 / 200 	 Time Taken: 1 sec
learning rate 0.0001010 -> 0.0000990
(epoch: 150, iters: 22, time: 0.055, data: 0.001) G_GAN: 1.958 G_L1: 8.809 D_real: 0.362 D_fake: 0.152 
saving the model at the end of epoch 150, iters 3300
End of epoch 150 / 200 	 Time Taken: 7 sec
learning rate 0.0000990 -> 0.0000970
End of epoch 151 / 200 	 Time Taken: 1 sec
learning rate 0.0000970 -> 0.0000950
End of epoch 152 / 200 	 Time Taken: 1 sec
learning rate 0.0000950 -> 0.0000931
End of epoch 153 / 200 	 Time Taken: 1 sec
learning rate 0.0000931 -> 0.0000911
End of epoch 154 / 200 	 Time Taken: 1 sec
learning rate 0.0000911 -> 0.0000891
(epoch: 155, iters: 12, time: 0.058, data: 0.194) G_GAN: 2.422 G_L1: 8.989 D_real: 0.052 D_fake: 0.269 
saving the model at the end of epoch 155, iters 3410
End of epoch 155 / 200 	 Time Taken: 3 sec
learning rate 0.0000891 -> 0.0000871
End of epoch 156 / 200 	 Time Taken: 1 sec
learning rate 0.0000871 -> 0.0000851
End of epoch 157 / 200 	 Time Taken: 1 sec
learning rate 0.0000851 -> 0.0000832
End of epoch 158 / 200 	 Time Taken: 1 sec
learning rate 0.0000832 -> 0.0000812
End of epoch 159 / 200 	 Time Taken: 1 sec
learning rate 0.0000812 -> 0.0000792
(epoch: 160, iters: 2, time: 0.050, data: 0.002) G_GAN: 1.356 G_L1: 9.928 D_real: 0.361 D_fake: 0.791 
saving the model at the end of epoch 160, iters 3520
End of epoch 160 / 200 	 Time Taken: 3 sec
learning rate 0.0000792 -> 0.0000772
End of epoch 161 / 200 	 Time Taken: 1 sec
learning rate 0.0000772 -> 0.0000752
End of epoch 162 / 200 	 Time Taken: 1 sec
learning rate 0.0000752 -> 0.0000733
End of epoch 163 / 200 	 Time Taken: 1 sec
learning rate 0.0000733 -> 0.0000713
(epoch: 164, iters: 14, time: 0.474, data: 0.000) G_GAN: 2.261 G_L1: 11.096 D_real: 0.026 D_fake: 0.206 
End of epoch 164 / 200 	 Time Taken: 1 sec
learning rate 0.0000713 -> 0.0000693
saving the model at the end of epoch 165, iters 3630
End of epoch 165 / 200 	 Time Taken: 3 sec
learning rate 0.0000693 -> 0.0000673
End of epoch 166 / 200 	 Time Taken: 1 sec
learning rate 0.0000673 -> 0.0000653
End of epoch 167 / 200 	 Time Taken: 1 sec
learning rate 0.0000653 -> 0.0000634
End of epoch 168 / 200 	 Time Taken: 1 sec
learning rate 0.0000634 -> 0.0000614
(epoch: 169, iters: 4, time: 0.057, data: 0.001) G_GAN: 1.998 G_L1: 7.259 D_real: 0.555 D_fake: 0.115 
End of epoch 169 / 200 	 Time Taken: 1 sec
learning rate 0.0000614 -> 0.0000594
saving the model at the end of epoch 170, iters 3740
End of epoch 170 / 200 	 Time Taken: 3 sec
learning rate 0.0000594 -> 0.0000574
End of epoch 171 / 200 	 Time Taken: 1 sec
learning rate 0.0000574 -> 0.0000554
End of epoch 172 / 200 	 Time Taken: 1 sec
learning rate 0.0000554 -> 0.0000535
(epoch: 173, iters: 16, time: 0.053, data: 0.001) G_GAN: 2.170 G_L1: 12.433 D_real: 0.000 D_fake: 0.242 
End of epoch 173 / 200 	 Time Taken: 1 sec
learning rate 0.0000535 -> 0.0000515
End of epoch 174 / 200 	 Time Taken: 1 sec
learning rate 0.0000515 -> 0.0000495
saving the model at the end of epoch 175, iters 3850
End of epoch 175 / 200 	 Time Taken: 2 sec
learning rate 0.0000495 -> 0.0000475
End of epoch 176 / 200 	 Time Taken: 1 sec
learning rate 0.0000475 -> 0.0000455
End of epoch 177 / 200 	 Time Taken: 1 sec
learning rate 0.0000455 -> 0.0000436
(epoch: 178, iters: 6, time: 0.058, data: 0.001) G_GAN: 2.710 G_L1: 11.173 D_real: 0.002 D_fake: 0.085 
End of epoch 178 / 200 	 Time Taken: 1 sec
learning rate 0.0000436 -> 0.0000416
End of epoch 179 / 200 	 Time Taken: 1 sec
learning rate 0.0000416 -> 0.0000396
saving the model at the end of epoch 180, iters 3960
End of epoch 180 / 200 	 Time Taken: 2 sec
learning rate 0.0000396 -> 0.0000376
End of epoch 181 / 200 	 Time Taken: 1 sec
learning rate 0.0000376 -> 0.0000356
(epoch: 182, iters: 18, time: 0.528, data: 0.000) G_GAN: 3.003 G_L1: 10.572 D_real: 0.199 D_fake: 0.076 
End of epoch 182 / 200 	 Time Taken: 1 sec
learning rate 0.0000356 -> 0.0000337
End of epoch 183 / 200 	 Time Taken: 1 sec
learning rate 0.0000337 -> 0.0000317
End of epoch 184 / 200 	 Time Taken: 1 sec
learning rate 0.0000317 -> 0.0000297
saving the model at the end of epoch 185, iters 4070
End of epoch 185 / 200 	 Time Taken: 3 sec
learning rate 0.0000297 -> 0.0000277
End of epoch 186 / 200 	 Time Taken: 1 sec
learning rate 0.0000277 -> 0.0000257
(epoch: 187, iters: 8, time: 0.058, data: 0.001) G_GAN: 3.129 G_L1: 21.879 D_real: 0.000 D_fake: 0.066 
End of epoch 187 / 200 	 Time Taken: 1 sec
learning rate 0.0000257 -> 0.0000238
End of epoch 188 / 200 	 Time Taken: 1 sec
learning rate 0.0000238 -> 0.0000218
End of epoch 189 / 200 	 Time Taken: 1 sec
learning rate 0.0000218 -> 0.0000198
saving the model at the end of epoch 190, iters 4180
End of epoch 190 / 200 	 Time Taken: 11 sec
learning rate 0.0000198 -> 0.0000178
(epoch: 191, iters: 20, time: 0.056, data: 0.002) G_GAN: 1.408 G_L1: 7.270 D_real: 1.047 D_fake: 0.271 
End of epoch 191 / 200 	 Time Taken: 1 sec
learning rate 0.0000178 -> 0.0000158
End of epoch 192 / 200 	 Time Taken: 1 sec
learning rate 0.0000158 -> 0.0000139
End of epoch 193 / 200 	 Time Taken: 1 sec
learning rate 0.0000139 -> 0.0000119
End of epoch 194 / 200 	 Time Taken: 1 sec
learning rate 0.0000119 -> 0.0000099
saving the model at the end of epoch 195, iters 4290
End of epoch 195 / 200 	 Time Taken: 7 sec
learning rate 0.0000099 -> 0.0000079
(epoch: 196, iters: 10, time: 0.056, data: 0.002) G_GAN: 3.488 G_L1: 22.000 D_real: 0.001 D_fake: 0.039 
End of epoch 196 / 200 	 Time Taken: 1 sec
learning rate 0.0000079 -> 0.0000059
End of epoch 197 / 200 	 Time Taken: 1 sec
learning rate 0.0000059 -> 0.0000040
End of epoch 198 / 200 	 Time Taken: 1 sec
learning rate 0.0000040 -> 0.0000020
End of epoch 199 / 200 	 Time Taken: 1 sec
learning rate 0.0000020 -> 0.0000000
(epoch: 200, iters: 22, time: 0.651, data: 0.001) G_GAN: 3.178 G_L1: 11.236 D_real: 0.069 D_fake: 0.056 
saving the model at the end of epoch 200, iters 4400
End of epoch 200 / 200 	 Time Taken: 3 sec
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 256                           
                 dataroot: ./datasets/sketchy            	[default: None]
             dataset_mode: aligned                       
                direction: BtoA                          	[default: AtoB]
          display_winsize: 256                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                         	[default: None]
                load_iter: 0                             	[default: 0]
                load_size: 256                           
         max_dataset_size: inf                           
                    model: pix2pix                       	[default: test]
               n_layers_D: 3                             
                     name: sketchy_pix2pix               	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 50                            
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: ./results/                    
           serial_batches: False                         
                   suffix:                               
                  verbose: False                         
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from ./checkpoints/sketchy_pix2pix/latest_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
creating web directory ./results/sketchy_pix2pix/test_latest
processing (0000)-th image... ['./datasets/sketchy/test/n01639765_3069.png']
processing (0005)-th image... ['./datasets/sketchy/test/n02129604_17637.png']
processing (0010)-th image... ['./datasets/sketchy/test/n02676566_4469.png']
processing (0015)-th image... ['./datasets/sketchy/test/n03495258_10889.png']
processing (0020)-th image... ['./datasets/sketchy/test/n04587559_9556.png']
